{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "env: findingzeke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt  \n",
    "from matplotlib.image import  imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPTokenizerFast, CLIPProcessor, CLIPModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = \"../images/test/zeke.png\"\n",
    "image_collection_path = \"../images/collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have CUDA or MPS, set it to the active device like this\n",
    "device = \"cuda\" if torch.cuda.is_available() else \\\n",
    "            (\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeCLIP():\n",
    "    \n",
    "    model_id = \"openai/clip-vit-base-patch32\" #https://huggingface.co/openai/clip-vit-base-patch32\n",
    "\n",
    "    # we initialize a tokenizer, image processor, and the model itself\n",
    "    tokenizer = CLIPTokenizerFast.from_pretrained(model_id) #Used for text embeddings, not relevant in this example.\n",
    "    processor = CLIPProcessor.from_pretrained(model_id) #Used for image embeddings\n",
    "    model = CLIPModel.from_pretrained(model_id).to(device) #CLIP model\n",
    "\n",
    "    return tokenizer, processor, model\n",
    "\n",
    "tokenizer, processor, model = initializeCLIP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageEmbedding(image_path, model):\n",
    "\n",
    "    image = processor(\n",
    "        text=None,\n",
    "        images=imread(image_path),\n",
    "        return_tensors='pt'\n",
    "    )['pixel_values'].to(device)\n",
    "\n",
    "    # image.shape\n",
    "    with torch.no_grad():\n",
    "        tensor_result = model.get_image_features(image)\n",
    "        tensor_result_cpu = tensor_result.to(\"cpu\")\n",
    "        tensor_result_cpu.shape\n",
    "        # print(tensor_result_cpu.squeeze(0).numpy())\n",
    "        vector = tensor_result_cpu.squeeze(0).numpy()\n",
    "        return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getImageEmbedding(image_path=test_image_path, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesInDirectory(directory_path):\n",
    "    \n",
    "    return glob.glob(os.path.join(directory_path, \"*.png\")  )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineSimilarity(vector_a, vector_b):  \n",
    "    # Calculate the dot product of the two vectors  \n",
    "    dot_product = np.dot(vector_a, vector_b)  \n",
    "      \n",
    "    # Calculate the magnitude (norm) of each vector  \n",
    "    norm_a = np.linalg.norm(vector_a)  \n",
    "    norm_b = np.linalg.norm(vector_b)  \n",
    "      \n",
    "    # Calculate the cosine similarity  \n",
    "    similarity = dot_product / (norm_a * norm_b)  \n",
    "      \n",
    "    return similarity  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all files in the directory\n",
    "file_collection = getFilesInDirectory(image_collection_path)\n",
    "print(f\"{len(file_collection)} files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_dictionary = {}\n",
    "\n",
    "embeddings_test_image = getImageEmbedding(image_path=test_image_path, model=model)\n",
    "print(f\"Embedding size: {len(embeddings_test_image)}\")\n",
    "\n",
    "for file in file_collection:\n",
    "    cosine_similarity = getCosineSimilarity(embeddings_test_image, getImageEmbedding(image_path=file, model=model))\n",
    "    # print(f\"file:{file}, cosine_similarity:{cosine_similarity}\")\n",
    "    cosine_similarity_dictionary[file] = cosine_similarity\n",
    "\n",
    "print(\"Embeddings generated and similarity calculated.\")\n",
    "print(type(cosine_similarity_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort descending\n",
    "sorted_data = sorted(cosine_similarity_dictionary.items(), key=lambda item: item[1], reverse=True)  \n",
    "print(type(sorted_data))\n",
    "\n",
    "#View sorted scores\n",
    "for index, (path, score) in enumerate(sorted_data):    \n",
    "    print(f\"{index}, {path}: {score}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"**Showing Zeke**\")\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(imread(test_image_path))  \n",
    "plt.title(f\"{test_image_path}\")\n",
    "plt.show()  \n",
    "\n",
    "\n",
    "top_N = 3\n",
    "\n",
    "print(f\"Showing top {top_N} best matches\")\n",
    "\n",
    "for index, (path, score) in enumerate(sorted_data[:top_N]):    \n",
    "\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(imread(path))  \n",
    "    plt.title(f\"{path}, {round(score,2)}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Showing least {top_N} matches\")\n",
    "\n",
    "for index, (path, score) in enumerate(sorted_data[-top_N:]):    \n",
    "\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(imread(path))  \n",
    "    plt.title(f\"{path}, {round(score,2)}\")\n",
    "    plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (findingzeke)",
   "language": "python",
   "name": "findingzeke"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
